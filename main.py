import asyncio
import os

import streamlit as st
from mcp.client.streamable_http import streamablehttp_client
from strands import Agent
from strands.models.openai import OpenAIModel
from strands.tools.mcp import MCPClient

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Microsoft Learning MCP Ã— Strands Agents SDK",
    page_icon="ğŸ“šğŸ¤–",
    initial_sidebar_state="expanded",
    menu_items={"About": "Microsoft Learning MCPã¨Strands Agents SDKã§AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½“é¨“ã§ãã‚‹ã‚¢ãƒ—ãƒªã ã‚ˆï¼"},
)

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
if "openai" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["openai"]["OPENAI_API_KEY"]

# LangSmithãƒˆãƒ¬ãƒ¼ã‚¹è¨­å®š
if "langsmith" in st.secrets:
    os.environ["LANGSMITH_API_KEY"] = st.secrets["langsmith"]["LANGSMITH_API_KEY"]
    
def setup_langsmith_tracing(api_key, project_name, enabled=True):
    """LangSmithãƒˆãƒ¬ãƒ¼ã‚¹æ©Ÿèƒ½ã‚’è¨­å®š"""
    if enabled and api_key and project_name:
        os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = "https://api.smith.langchain.com/otel"
        os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"x-api-key={api_key},Langsmith-Project={project_name}"
        os.environ["OTEL_SERVICE_NAME"] = "strands-mcp-agent"
        os.environ["STRANDS_OTEL_SAMPLER_RATIO"] = "0.2"
        return True
    else:
        # ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ç„¡åŠ¹åŒ–
        for env_var in ["OTEL_EXPORTER_OTLP_ENDPOINT", "OTEL_EXPORTER_OTLP_HEADERS", "OTEL_SERVICE_NAME", "STRANDS_OTEL_SAMPLER_RATIO"]:
            if env_var in os.environ:
                del os.environ[env_var]
        return False

# Microsoft Learning MCPè¨­å®šï¼ˆå›ºå®šï¼‰
MICROSOFT_LEARNING_MCP_URL = "https://learn.microsoft.com/api/mcp"


def create_mcp_client(mcp_url):
    """MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆï¼ˆHTTPå½¢å¼ï¼‰"""

    def transport():
        return streamablehttp_client(mcp_url)

    return MCPClient(transport)


def create_agent(clients):
    """è¤‡æ•°ã®MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ãƒ„ãƒ¼ãƒ«ã‚’é›†ç´„ã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ"""
    all_tools = []
    for client in clients:
        tools = client.list_tools_sync()
        all_tools.extend(tools)

    model = OpenAIModel(
        client_args={
            "api_key": os.getenv("OPENAI_API_KEY"),
        },
        model_id="gpt-4.1",
        params={
            "max_tokens": 1000,
            "temperature": 0.5,
        },
    )
    return Agent(model=model, tools=all_tools)


def extract_tool_info(chunk):
    """ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰ãƒ„ãƒ¼ãƒ«æƒ…å ±ã‚’æŠ½å‡º"""
    event = chunk.get("event", {})
    if "contentBlockStart" in event:
        tool_use = event["contentBlockStart"].get("start", {}).get("toolUse", {})
        return tool_use.get("toolUseId"), tool_use.get("name")
    return None, None


def extract_text(chunk):
    """ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    if text := chunk.get("data"):
        return text
    elif delta := chunk.get("delta", {}).get("text"):
        return delta
    return ""


async def stream_response(agent, question):
    """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºã—ã€å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™"""
    text_holder = st.empty()
    buffer = ""
    full_response = ""
    shown_tools = set()

    async for chunk in agent.stream_async(question):
        if isinstance(chunk, dict):
            tool_id, tool_name = extract_tool_info(chunk)
            if tool_id and tool_name and tool_id not in shown_tools:
                shown_tools.add(tool_id)
                if buffer:
                    text_holder.markdown(buffer)
                    full_response += buffer
                    buffer = ""
                st.info(f"ğŸ”§ **{tool_name}** ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œä¸­...")
                text_holder = st.empty()

            if text := extract_text(chunk):
                buffer += text
                text_holder.markdown(buffer)

    if buffer:
        full_response += buffer
        text_holder.markdown(buffer)

    return full_response


# --- Sidebar: LangSmithãƒˆãƒ¬ãƒ¼ã‚¹è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    st.subheader("ğŸ” LangSmithãƒˆãƒ¬ãƒ¼ã‚¹")
    langsmith_enabled = st.checkbox("LangSmithãƒˆãƒ¬ãƒ¼ã‚¹ã‚’æœ‰åŠ¹åŒ–", value=False)
    
    langsmith_api_key = ""
    langsmith_project = ""
    
    if langsmith_enabled:
        # ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å–å¾—
        default_api_key = os.environ.get("LANGSMITH_API_KEY", "")
        langsmith_api_key = st.text_input(
            "LangSmith API Key", 
            value=default_api_key,
            type="password",
            help="LangSmithã®API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        langsmith_project = st.text_input(
            "Project Name", 
            value="strands-mcp-agent",
            help="LangSmithã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        
        if langsmith_api_key and langsmith_project:
            tracing_setup = setup_langsmith_tracing(langsmith_api_key, langsmith_project, True)
            if tracing_setup:
                st.success("âœ… LangSmithãƒˆãƒ¬ãƒ¼ã‚¹ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸ")
            else:
                st.error("âŒ LangSmithãƒˆãƒ¬ãƒ¼ã‚¹ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ")
        else:
            st.warning("âš ï¸ API Keyã¨Project Nameã®ä¸¡æ–¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        setup_langsmith_tracing("", "", False)

# --- App ---
st.title("Microsoft Learning Agent")
st.markdown(
    "ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€MS Learnã®MCP APIã‚’ä½¿ã£ã¦Azureã®è³‡æ ¼å‹‰å¼·ã‚„å­¦ç¿’ã‚µãƒãƒ¼ãƒˆã‚‚ã§ãã¡ã‚ƒã†ã‚ˆï¼\n"
    "\nğŸ’¡ Azureã®å…¬å¼ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æ•™æã‚’æ´»ç”¨ã—ã¦ã€è³‡æ ¼å–å¾—ã‚’ç›®æŒ‡ãã†ï¼"
)

# LangSmithãƒˆãƒ¬ãƒ¼ã‚¹çŠ¶æ…‹ã®è¡¨ç¤º
if langsmith_enabled and langsmith_api_key and langsmith_project:
    st.info(f"ğŸ” **LangSmithãƒˆãƒ¬ãƒ¼ã‚¹æœ‰åŠ¹** - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {langsmith_project}")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# å±¥æ­´ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¦è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”
    with st.chat_message("assistant"):
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­â€¦"):
            client = create_mcp_client(MICROSOFT_LEARNING_MCP_URL)
            clients = [client]
            try:
                for client in clients:
                    client.__enter__()

                agent = create_agent(clients)

                # éåŒæœŸã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
                response = asyncio.run(stream_response(agent, prompt))

                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å®Œå…¨ãªå¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
                st.session_state.messages.append({"role": "assistant", "content": response})

            except asyncio.TimeoutError:
                st.error("ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.info("Microsoft Learning MCPã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            finally:
                for client in clients:
                    try:
                        client.__exit__(None, None, None)
                    except Exception:
                        pass
